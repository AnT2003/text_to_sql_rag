import os
import json
import glob
import datetime
import re  # <--- B·∫Øt bu·ªôc c√≥ ƒë·ªÉ tr√≠ch xu·∫•t t√™n t·ª´ DDL
from flask import Flask, render_template, request, jsonify
from dotenv import load_dotenv
from ollama import Client
from flask_cors import CORS
from flask_sqlalchemy import SQLAlchemy
from sqlalchemy import desc
from rank_bm25 import BM25Okapi  # Th∆∞ vi·ªán RAG t·ªëi ∆∞u

# =========================================================
#  PH·∫¶N 1: CONFIG & SETUP
# =========================================================

load_dotenv()
app = Flask(__name__)
CORS(app)

db_url = os.getenv("DATABASE_URL")
if not db_url:
    db_url = "sqlite:///local_chat.db"
if db_url.startswith("postgres://"):
    db_url = db_url.replace("postgres://", "postgresql://", 1)

app.config['SQLALCHEMY_DATABASE_URI'] = db_url  
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

db = SQLAlchemy(app)

OLLAMA_HOST = "https://ollama.com"
MODEL_NAME = "gemini-3-flash-preview:latest"
DEFAULT_API_KEY = os.getenv("OLLAMA_API_KEY")
SCHEMA_FOLDER = "./schemas"

# BI·∫æN TO√ÄN C·ª§C
SCHEMA_DOCS = []        # List ch·ª©a c√°c ƒëo·∫°n text schema
BM25_MODEL = None       # Model t√¨m ki·∫øm

# =========================================================
#  PH·∫¶N 2: DATABASE MODELS
# =========================================================

class Session(db.Model):
    __tablename__ = 'sessions'
    id = db.Column(db.String(50), primary_key=True)
    title = db.Column(db.String(200))
    created_at = db.Column(db.DateTime, default=datetime.datetime.utcnow)

class Message(db.Model):
    __tablename__ = 'messages'
    id = db.Column(db.Integer, primary_key=True)
    session_id = db.Column(db.String(50), db.ForeignKey('sessions.id',ondelete="CASCADE"), nullable=False)
    role = db.Column(db.String(20), nullable=False)
    content = db.Column(db.Text, nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.datetime.utcnow)

def init_db():
    with app.app_context():
        db.create_all()

def save_message(session_id, role, content):
    try:
        new_msg = Message(session_id=session_id, role=role, content=content)
        db.session.add(new_msg)
        db.session.commit()
    except:
        db.session.rollback()

def create_session_if_not_exists(session_id, first_msg):
    try:
        if not Session.query.get(session_id):
            title = (first_msg[:50] + '...') if len(first_msg) > 50 else first_msg
            db.session.add(Session(id=session_id, title=title))
            db.session.commit()
    except:
        db.session.rollback()

def get_chat_history_formatted(session_id, limit=10):
    try:
        msgs = Message.query.filter_by(session_id=session_id).order_by(desc(Message.created_at)).limit(limit).all()
        return [{"role": m.role, "content": m.content} for m in msgs[::-1]]
    except:
        return []

# =========================================================
#  PH·∫¶N 3: LOGIC LOAD SCHEMA (S·ª¨ D·ª§NG REGEX TR√çCH XU·∫§T T·ª™ DDL)
# =========================================================

def load_all_schemas():
    """
    Load schema t·ª´ JSON. V√¨ JSON kh√¥ng c√≥ tableReference, ta d√πng Regex 
    ƒë·ªÉ 'b√≥c' t√™n b·∫£ng ƒë·∫ßy ƒë·ªß t·ª´ chu·ªói DDL.
    """
    global SCHEMA_DOCS
    print("üöÄ ƒêang n·∫°p v√† x·ª≠ l√Ω DDL t·ª´ Schemas...")

    if not os.path.exists(SCHEMA_FOLDER):
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {SCHEMA_FOLDER}")
        return

    json_files = glob.glob(os.path.join(SCHEMA_FOLDER, "*.json"))
    schema_parts = []

    for file_path in json_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                items = data if isinstance(data, list) else [data]

                for item in items:
                    # 1. X·ª¨ L√ù TABLE / VIEW
                    if 'table_name' in item and 'ddl' in item:
                        ddl = item['ddl']
                        table_name_short = item['table_name']
                        
                        # --- MAGIC REGEX ---
                        # T√¨m chu·ªói n·∫±m gi·ªØa d·∫•u backtick (`) sau ch·ªØ TABLE ho·∫∑c VIEW
                        # Pattern n√†y b·∫Øt ƒë∆∞·ª£c: CREATE EXTERNAL TABLE `a.b.c` ho·∫∑c CREATE VIEW `a.b.c`
                        match = re.search(r'CREATE.*?(?:TABLE|VIEW)\s+`([^`]+)`', ddl, re.IGNORECASE | re.DOTALL)
                        
                        if match:
                            # L·∫•y ƒë∆∞·ª£c: kynaforkids-server-production.kynaforkids.Acc_LTV_CAC
                            full_table_name = f"`{match.group(1)}`"
                        else:
                            # Fallback n·∫øu DDL d·ªã bi·ªát (√≠t x·∫£y ra v·ªõi BigQuery export)
                            full_table_name = f"`{table_name_short}`"

                        table_type = item.get('table_type', 'TABLE')
                        
                        cols = []
                        raw_columns = item.get('columns')
                        col_tokens = [] # D√πng ƒë·ªÉ ƒë√°nh index t√¨m ki·∫øm
                        
                        if raw_columns:
                            try:
                                parsed_columns = json.loads(raw_columns)
                                if isinstance(parsed_columns, list):
                                    for col in parsed_columns:
                                        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p col l√† string ho·∫∑c dict
                                        c_name = col if isinstance(col, str) else col.get('name')
                                        cols.append(f"- `{c_name}`")
                                        col_tokens.append(c_name)
                            except: pass
                        
                        columns_block = "\n".join(cols)
                        
                        # N·ªôi dung ƒë·ªÉ AI ƒë·ªçc
                        content_block = f"""
                        [TABLE ENTITY]
                        Table Name: {full_table_name}
                        Table Type: {table_type}
                        Source DDL:
                        ```sql
                        {ddl}
                        ```
                        COLUMNS:
                        {columns_block}
                        """
                        
                        # D·ªØ li·ªáu ƒë·ªÉ RAG ƒë√°nh index (Full name + short name + columns)
                        # clean_text gi√∫p BM25 hi·ªÉu ƒë∆∞·ª£c c√°c t·ª´ d√≠nh nhau b·∫±ng d·∫•u ch·∫•m
                        search_text = f"{full_table_name.replace('.', ' ')} {table_name_short} {' '.join(col_tokens)}"
                        
                        schema_parts.append({"text": content_block, "search_text": search_text})

                    # 2. X·ª¨ L√ù ROUTINE / FUNCTION
                    elif 'routine_name' in item:
                        # T∆∞∆°ng t·ª±, n·∫øu Routine c√≥ DDL th√¨ tr√≠ch xu·∫•t, n·∫øu kh√¥ng th√¨ t·ª± gh√©p
                        routine_name = item.get('routine_name')
                        ddl = item.get('ddl', '')
                        definition = item.get('routine_definition', '')
                        
                        # Regex t√¨m t√™n function trong DDL
                        match = re.search(r'CREATE.*?FUNCTION\s+`([^`]+)`', ddl, re.IGNORECASE | re.DOTALL)
                        if match:
                             full_routine_name = f"`{match.group(1)}`"
                        else:
                             full_routine_name = f"`{routine_name}`"

                        content_block = f"""
                        [LOGIC ROUTINE]
                        Routine Name: {full_routine_name}
                        Definition:
                        {definition}
                        """
                        search_text = f"{full_routine_name.replace('.', ' ')} {definition}"
                        schema_parts.append({"text": content_block, "search_text": search_text})

        except Exception as e:
            print(f"‚ùå L·ªói file {file_path}: {e}")

    SCHEMA_DOCS = schema_parts
    # X√¢y d·ª±ng Index ngay
    build_rag_index()

# =========================================================
#  PH·∫¶N 4: RAG ENGINE (BM25)
# =========================================================

def tokenize_query(text):
    """T√°ch t·ª´: x√≥a k√Ω t·ª± ƒë·∫∑c bi·ªát, t√°ch camelCase, x√≥a stopword"""
    text = re.sub(r'[\.\_\-\(\)\,\`]', ' ', str(text))
    text = re.sub(r'([a-z])([A-Z])', r'\1 \2', text)
    tokens = text.lower().split()
    stopwords = {'create', 'table', 'view', 'select', 'external', 'float64', 'string', 'date'}
    return [t for t in tokens if t not in stopwords]

def build_rag_index():
    global BM25_MODEL, SCHEMA_DOCS
    if not SCHEMA_DOCS: return
    
    # Tokenize field 'search_text' ta ƒë√£ chu·∫©n b·ªã ·ªü tr√™n
    tokenized_corpus = [tokenize_query(doc['search_text']) for doc in SCHEMA_DOCS]
    BM25_MODEL = BM25Okapi(tokenized_corpus)
    print(f"‚úÖ ƒê√£ index {len(SCHEMA_DOCS)} schemas th√†nh c√¥ng.")

def retrieve_schema_smart(question, top_k=5):
    if not BM25_MODEL or not SCHEMA_DOCS: return ""
    
    tokenized_query = tokenize_query(question)
    doc_scores = BM25_MODEL.get_scores(tokenized_query)
    
    # L·∫•y top k index c√≥ ƒëi·ªÉm cao nh·∫•t
    top_indices = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:top_k]
    
    # L·ªçc b·ªè nh·ªØng k·∫øt qu·∫£ ƒëi·ªÉm = 0 (kh√¥ng li√™n quan t√≠ n√†o)
    results = [SCHEMA_DOCS[i]['text'] for i in top_indices if doc_scores[i] > 0]
    
    # Fallback: N·∫øu kh√¥ng t√¨m th·∫•y g√¨, l·∫•y ƒë·∫°i 2 c√°i ƒë·∫ßu (ƒë·ªÉ AI kh√¥ng b·ªã blank context)
    if not results:
        results = [d['text'] for d in SCHEMA_DOCS[:2]]
        
    return "\n--------------------\n".join(results)

# Kh·ªüi t·∫°o
init_db()
load_all_schemas()

# =========================================================
#  PH·∫¶N 5: API ROUTES
# =========================================================

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/sessions', methods=['GET'])
def get_sessions():
    sessions = Session.query.order_by(desc(Session.created_at)).all()
    return jsonify([{'id': s.id, 'title': s.title} for s in sessions])

@app.route('/api/history/<session_id>', methods=['GET'])
def get_history(session_id):
    return jsonify(get_chat_history_formatted(session_id, limit=50))

@app.route('/api/clear_history', methods=['POST'])
def clear_history():
    try:
        Message.query.delete()
        Session.query.delete()
        db.session.commit()
        return jsonify({"status": "success"})
    except: return jsonify({"error": "err"}), 500

@app.route("/api/session/<session_id>", methods=["DELETE"])
def delete_session(session_id):
    try:
        Message.query.filter_by(session_id=session_id).delete()
        Session.query.filter_by(id=session_id).delete()
        db.session.commit()
        return jsonify({"status": "success"})
    except: return jsonify({"error": "err"}), 500

@app.route('/api/reload', methods=['POST'])
def reload_schema_api():
    load_all_schemas()
    return jsonify({"status": "success", "message": "Schemas reloaded!"})

@app.route('/api/chat', methods=['POST'])
def chat():
    data = request.json
    api_key = data.get('api_key') or DEFAULT_API_KEY
    user_msg = data.get('message')
    session_id = data.get('session_id')

    if not api_key or not session_id:
        return jsonify({"error": "Missing info"}), 400

    # 1. RETRIEVAL (BM25)
    retrieved_context = retrieve_schema_smart(user_msg, top_k=5)

    create_session_if_not_exists(session_id, user_msg)
    save_message(session_id, "user", user_msg)

    # 2. PROMPT
    # L∆∞u √Ω: Ph·∫ßn Prompt n√†y nh·∫•n m·∫°nh vi·ªác COPY t√™n b·∫£ng t·ª´ context
    system_prompt = f"""Role: BigQuery SQL Expert.
Nhi·ªám v·ª•: Chuy·ªÉn c√¢u h·ªèi ng∆∞·ªùi d√πng th√†nh c√¢u l·ªánh SQL Standard.

[DATABASE SCHEMA - RELEVANT CONTEXT]:
{retrieved_context}

[QUY T·∫ÆC B·∫ÆT BU·ªòC]:
1. **FULL NAME ONLY**: Ph·∫£i d√πng t√™n b·∫£ng ƒë·∫ßy ƒë·ªß CH√çNH X√ÅC nh∆∞ trong ph·∫ßn 'Table Name:' ·ªü tr√™n (v√≠ d·ª•: `project.dataset.table`).
   - Tuy·ªát ƒë·ªëi KH√îNG d√πng t√™n vi·∫øt t·∫Øt ki·ªÉu `..table` hay `.table`.
   - N·∫øu trong schema ghi `UnknownDataset.table`, h√£y d√πng y nguy√™n `UnknownDataset.table`.
2. **Logic Mapping**: ƒê·ªçc k·ªπ ph·∫ßn [LOGIC ROUTINE] (n·∫øu c√≥) ƒë·ªÉ map c√°c tr·∫°ng th√°i (status, type) sang s·ªë/m√£ t∆∞∆°ng ·ª©ng trong WHERE clause.
3. **Syntax**: D√πng Google Standard SQL.

User Question: {user_msg}

[ƒê·ªäNH D·∫†NG TR·∫¢ V·ªÄ]:
Ch·ªâ tr·∫£ v·ªÅ code SQL trong ```sql ... ```. Sau khi tr·∫£ k·∫øt qu·∫£ SQL n√™n c√≥ th√™m ph·∫ßn gi·∫£i th√≠ch ng·∫Øn g·ªçn.
"""

    messages_payload = [{"role": "system", "content": system_prompt}]
    history = get_chat_history_formatted(session_id, limit=6)
    for msg in history:
        if msg['content'] != user_msg:
            messages_payload.append(msg)
    messages_payload.append({"role": "user", "content": user_msg})

    try:
        client = Client(host=OLLAMA_HOST, headers={"Authorization": f"Bearer {api_key}"})
        response = client.chat(
            model=MODEL_NAME,
            messages=messages_payload,
            stream=False,
            options={"temperature": 0.0}
        )
        reply = response['message']['content']
        save_message(session_id, "assistant", reply)
        return jsonify({"response": reply})

    except Exception as e:
        print(f"Error: {e}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    init_db()
    load_all_schemas()
    app.run(debug=True, port=5000)
