import os
import json
import glob
import sqlite3
import datetime
from flask import Flask, render_template, request, jsonify
from dotenv import load_dotenv
from ollama import Client

# --- 1. SETUP M√îI TR∆Ø·ªúNG ---
load_dotenv()
app = Flask(__name__)

# --- 2. C·∫§U H√åNH H·ªÜ TH·ªêNG ---
SCHEMA_FOLDER = "./schemas"
DB_FILE = "chat_history.db"
# C·∫•u h√¨nh Ollama (Cloud ho·∫∑c Local)
OLLAMA_HOST = "https://ollama.com"
MODEL_NAME = "gpt-oss:120b"
# API Key (∆Øu ti√™n l·∫•y t·ª´ .env)
DEFAULT_API_KEY = os.getenv("OLLAMA_API_KEY") 

# BI·∫æN TO√ÄN C·ª§C: 
# Thay v√¨ l∆∞u 1 chu·ªói string kh·ªïng l·ªì, ta l∆∞u d·∫°ng danh s√°ch ƒë·ªÉ t√¨m ki·∫øm
GLOBAL_SCHEMA_DOCS = []  # Ch·ª©a chi ti·∫øt t·ª´ng b·∫£ng/h√†m
GLOBAL_TABLE_NAMES = []  # Ch·ª©a danh s√°ch t√™n r√∫t g·ªçn

# Gi·ªõi h·∫°n Token an to√†n (∆∞·ªõc l∆∞·ª£ng k√Ω t·ª±) ƒë·ªÉ kh√¥ng b·ªã l·ªói 400
MAX_CONTEXT_CHARS = 50000 

# =========================================================
#  PH·∫¶N 3: QU·∫¢N L√ù DATABASE (SQLITE) - L∆ØU L·ªäCH S·ª¨ CHAT
# =========================================================
def init_db():
    """Kh·ªüi t·∫°o database SQLite n·∫øu ch∆∞a c√≥"""
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS sessions 
                 (id TEXT PRIMARY KEY, title TEXT, created_at DATETIME)''')
    c.execute('''CREATE TABLE IF NOT EXISTS messages 
                 (id INTEGER PRIMARY KEY AUTOINCREMENT, session_id TEXT, role TEXT, content TEXT, created_at DATETIME)''')
    conn.commit()
    conn.close()

def get_chat_history_formatted(session_id, limit=10):
    """L·∫•y l·ªãch s·ª≠ chat c·ªßa m·ªôt phi√™n c·ª• th·ªÉ"""
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    c = conn.cursor()
    c.execute("SELECT role, content FROM messages WHERE session_id = ? ORDER BY created_at DESC LIMIT ?", (session_id, limit))
    rows = c.fetchall()
    conn.close()
    
    history = []
    # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ x·∫øp theo th·ª© t·ª± th·ªùi gian c≈© -> m·ªõi (User h·ªèi -> AI tr·∫£ l·ªùi)
    for r in rows[::-1]:
        history.append({"role": r["role"], "content": r["content"]})
    return history

def save_message(session_id, role, content):
    """L∆∞u tin nh·∫Øn v√†o DB"""
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("INSERT INTO messages (session_id, role, content, created_at) VALUES (?, ?, ?, ?)", 
              (session_id, role, content, datetime.datetime.now()))
    conn.commit()
    conn.close()

def create_session_if_not_exists(session_id, first_msg):
    """T·∫°o phi√™n chat m·ªõi n·∫øu ch∆∞a t·ªìn t·∫°i"""
    conn = sqlite3.connect(DB_FILE)
    c = conn.cursor()
    c.execute("SELECT id FROM sessions WHERE id = ?", (session_id,))
    if not c.fetchone():
        # L·∫•y 50 k√Ω t·ª± ƒë·∫ßu c·ªßa tin nh·∫Øn l√†m ti√™u ƒë·ªÅ
        c.execute("INSERT INTO sessions (id, title, created_at) VALUES (?, ?, ?)", 
                  (session_id, first_msg[:50], datetime.datetime.now()))
        conn.commit()
    conn.close()

# =========================================================
#  PH·∫¶N 4: K·ª∏ THU·∫¨T RAG & LOADING
# =========================================================
def load_all_schemas():
    """
    Load schemas v√†o b·ªô nh·ªõ nh∆∞ng chia nh·ªè th√†nh list ƒë·ªÉ t√¨m ki·∫øm (Retrieval)
    thay v√¨ g·ªôp t·∫•t c·∫£ th√†nh 1 c·ª•c text kh·ªïng l·ªì.
    """
    global GLOBAL_SCHEMA_DOCS, GLOBAL_TABLE_NAMES
    GLOBAL_SCHEMA_DOCS = []
    GLOBAL_TABLE_NAMES = []
    
    print("üöÄ ƒêang n·∫°p Schemas v√†o b·ªô nh·ªõ (Indexing mode)...")
    
    if not os.path.exists(SCHEMA_FOLDER): 
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {SCHEMA_FOLDER}")
        return

    json_files = glob.glob(os.path.join(SCHEMA_FOLDER, "*.json"))
    
    for file_path in json_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                items = data if isinstance(data, list) else [data]
                
                for item in items:
                    doc_content = ""
                    search_text = ""
                    doc_name = ""
                    
                    # --- X·ª¨ L√ù TABLE ---
                    if 'table_name' in item:
                        name = item.get('table_name', 'Unknown')
                        ddl = item.get('ddl', '')
                        doc_name = name
                        GLOBAL_TABLE_NAMES.append(name)
                        
                        doc_content = f"""
[TABLE SCHEMA]
Name: `{name}`
DDL:
```sql
{ddl}
```
"""
                        # Text d√πng ƒë·ªÉ search keyword
                        search_text = (name + " " + ddl).lower()
                    
                    # --- X·ª¨ L√ù ROUTINE ---
                    elif 'routine_name' in item:
                        name = item.get('routine_name', 'Unknown')
                        routine_def = item.get('routine_definition', '')
                        ddl = item.get('ddl', '')
                        arguments = item.get('arguments', [])
                        doc_name = name
                        
                        args_str = json.dumps(arguments, ensure_ascii=False) if isinstance(arguments, (list, dict)) else str(arguments)
                        
                        doc_content = f"""
[ROUTINE / FUNCTION]
Name: `{name}`
Arguments: {args_str}
Routine Definition:
```sql
{routine_def}
```
DDL:
```sql
{ddl}
```
(AI NOTE: H√£y ƒë·ªçc k·ªπ code SQL tr√™n. N·∫øu c√≥ CASE WHEN, h√£y d√πng n√≥ ƒë·ªÉ map gi√° tr·ªã ID t∆∞∆°ng ·ª©ng)
"""
                        # Text d√πng ƒë·ªÉ search keyword
                        search_text = (name + " " + routine_def + " " + ddl).lower()

                    if doc_content:
                        GLOBAL_SCHEMA_DOCS.append({
                            "name": doc_name,
                            "content": doc_content,
                            "search_text": search_text
                        })

        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc file {file_path}: {e}")

    print(f"‚úÖ ƒê√£ index xong {len(GLOBAL_SCHEMA_DOCS)} ƒë·ªëi t∆∞·ª£ng schema.")

def get_relevant_schemas(user_msg):
    """
    H√†m t√¨m ki·∫øm th√¥ng minh: Ch·ªâ l·∫•y nh·ªØng Schema c√≥ li√™n quan ƒë·∫øn c√¢u h·ªèi.
    Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ 'Prompt too long'.
    """
    if not GLOBAL_SCHEMA_DOCS:
        return "No schema data loaded."
    
    query_tokens = user_msg.lower().split()
    scored_docs = []
    
    # 1. Ch·∫•m ƒëi·ªÉm s·ª± li√™n quan
    for doc in GLOBAL_SCHEMA_DOCS:
        score = 0
        for token in query_tokens:
            # N·∫øu t·ª´ kh√≥a xu·∫•t hi·ªán trong t√™n b·∫£ng ho·∫∑c n·ªôi dung DDL -> tƒÉng ƒëi·ªÉm
            if token in doc['search_text']:
                score += 1
        scored_docs.append((score, doc))
    
    # 2. S·∫Øp x·∫øp: ƒêi·ªÉm cao l√™n ƒë·∫ßu
    scored_docs.sort(key=lambda x: x[0], reverse=True)
    
    # 3. Ch·ªçn l·ªçc: L·∫•y top docs sao cho kh√¥ng qu√° gi·ªõi h·∫°n k√Ω t·ª±
    selected_contents = []
    current_chars = 0
    
    # Lu√¥n l·∫•y √≠t nh·∫•t top 5 b·∫£ng li√™n quan nh·∫•t, ho·∫∑c nhi·ªÅu h∆°n n·∫øu c√≤n d∆∞ ch·ªó
    for score, doc in scored_docs:
        # L·∫•y nh·ªØng b·∫£ng c√≥ match keyword (score > 0) 
        # Ho·∫∑c l·∫•y t·ªëi thi·ªÉu 3 b·∫£ng ƒë·∫ßu ti√™n n·∫øu kh√¥ng match g√¨ c·∫£ (ƒë·ªÉ AI kh√¥ng b·ªã m√π)
        if score > 0 or len(selected_contents) < 3:
            if current_chars + len(doc['content']) < MAX_CONTEXT_CHARS:
                selected_contents.append(doc['content'])
                current_chars += len(doc['content'])
            else:
                break # ƒê√£ ƒë·∫ßy b·ªô nh·ªõ context cho ph√©p
    
    return "\n----------------------------------------\n".join(selected_contents)

# --- KH·ªûI CH·∫†Y L·∫¶N ƒê·∫¶U ---
init_db()
load_all_schemas()

# =========================================================
#  PH·∫¶N 5: API ROUTES & LOGIC CHAT
# =========================================================

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/sessions', methods=['GET'])
def get_sessions():
    conn = sqlite3.connect(DB_FILE)
    conn.row_factory = sqlite3.Row
    c = conn.cursor()
    rows = c.execute("SELECT * FROM sessions ORDER BY created_at DESC").fetchall()
    conn.close()
    return jsonify([dict(r) for r in rows])

@app.route('/api/history/<session_id>', methods=['GET'])
def get_history(session_id): 
    return jsonify(get_chat_history_formatted(session_id, limit=50))

@app.route('/api/chat', methods=['POST'])
def chat():
    # S·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c
    global GLOBAL_TABLE_NAMES
    
    data = request.json
    api_key = data.get('api_key') or DEFAULT_API_KEY
    user_msg = data.get('message')
    session_id = data.get('session_id')

    if not api_key: return jsonify({"error": "Thi·∫øu API Key"}), 401
    if not session_id: return jsonify({"error": "Thi·∫øu Session ID"}), 400

    try:
        # 1. L∆∞u Session v√† Tin nh·∫Øn User
        create_session_if_not_exists(session_id, user_msg)
        save_message(session_id, "user", user_msg)

        # 2. L·∫§Y CONTEXT LI√äN QUAN (RAG)
        # Thay v√¨ ƒë∆∞a to√†n b·ªô, ch·ªâ ƒë∆∞a nh·ªØng g√¨ c·∫ßn thi·∫øt
        relevant_schema_context = get_relevant_schemas(user_msg)
        all_tables_list = ", ".join(GLOBAL_TABLE_NAMES)

        # 3. X√ÇY D·ª∞NG PROMPT
        system_prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia BigQuery SQL cao c·∫•p.

[DANH S√ÅCH TO√ÄN B·ªò C√ÅC B·∫¢NG HI·ªÜN C√ì]:
{all_tables_list}

[CHI TI·∫æT SCHEMA & H√ÄM LI√äN QUAN ƒê·∫æN C√ÇU H·ªéI]:
(H·ªá th·ªëng ƒë√£ t·ª± ƒë·ªông l·ªçc b·ªõt c√°c b·∫£ng kh√¥ng li√™n quan ƒë·ªÉ t·ªëi ∆∞u b·ªô nh·ªõ)
{relevant_schema_context}

[Y√äU C·∫¶U]:
Vi·∫øt c√¢u l·ªánh SQL Standard tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa user.

[QUY T·∫ÆC QUAN TR·ªåNG - B·∫ÆT BU·ªòC TU√ÇN TH·ª¶]:
1. **Logic Mapping (QUAN TR·ªåNG NH·∫§T):**
   - H√£y t·ª± ƒë·ªçc ph·∫ßn `[ROUTINE / FUNCTION]` ·ªü tr√™n.
   - T√¨m c√°c m·ªánh ƒë·ªÅ `CASE WHEN` b√™n trong code SQL c·ªßa routine ƒë·ªÉ hi·ªÉu √Ω nghƒ©a c√°c con s·ªë (ID).
   - V√≠ d·ª•: N·∫øu th·∫•y `WHEN status_id = 2 THEN 'New'`, v√† user h·ªèi v·ªÅ 'New', b·∫°n PH·∫¢I d√πng `status_id = 2`.
   - KH√îNG ƒê∆Ø·ª¢C ƒêO√ÅN M√í. N·∫øu routine ƒë·ªãnh nghƒ©a kh√°c, h√£y theo routine.

2. **K·ªπ thu·∫≠t BigQuery:**
   - ‚ùå KH√îNG d√πng Correlated Subqueries (Subquery ph·ª• thu·ªôc b·∫£ng ngo√†i).
   - ‚úÖ D√πng JOIN (LEFT JOIN) k·∫øt h·ª£p GROUP BY n·∫øu c·∫ßn.
   - Ph·∫£i s·ª≠ d·ª•ng c√°c h√†m, syntax theo chu·∫©n c·∫•u tr√∫c c·ªßa BigQuery.

3. Ch·ªâ tr·∫£ v·ªÅ code SQL trong ```sql ... ```.

4. C√≥ th·ªÉ gi·∫£i th√≠ch ng·∫Øn g·ªçn sau ph·∫ßn code n·∫øu c·∫ßn thi·∫øt.
"""

        messages_payload = [{"role": "system", "content": system_prompt}]
        
        # Th√™m l·ªãch s·ª≠ chat
        history = get_chat_history_formatted(session_id, limit=10)
        for msg in history:
            if msg['content'] != user_msg: 
                messages_payload.append(msg)
        
        messages_payload.append({"role": "user", "content": user_msg})

        # 4. G·ªçi AI
        client = Client(host=OLLAMA_HOST, headers={"Authorization": f"Bearer {api_key}"})
        
        response = client.chat(
            model=MODEL_NAME, 
            messages=messages_payload, 
            stream=False, 
            options={"temperature": 0.1}
        )
        
        ai_reply = response['message']['content']
        save_message(session_id, "assistant", ai_reply)

        return jsonify({"response": ai_reply})

    except Exception as e:
        print(f"L·ªói Server: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/reload', methods=['POST'])
def reload_schema():
    load_all_schemas()
    return jsonify({"status": "success", "message": "ƒê√£ n·∫°p l·∫°i v√† index d·ªØ li·ªáu Schema!"})

if __name__ == '__main__':
    app.run(debug=True, port=5000)

