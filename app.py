import os
import json
import glob
import datetime
import psycopg2
from psycopg2.extras import RealDictCursor
from flask import Flask, render_template, request, jsonify
from dotenv import load_dotenv
from ollama import Client

# --- 1. SETUP M√îI TR∆Ø·ªúNG ---
load_dotenv()
app = Flask(__name__)

# --- 2. C·∫§U H√åNH H·ªÜ TH·ªêNG ---
SCHEMA_FOLDER = "./schemas"

# C·∫•u h√¨nh Database (PostgreSQL) - L·∫•y t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
# Tr√™n Render/Heroku, bi·∫øn n√†y s·∫Ω t·ª± ƒë·ªông ƒë∆∞·ª£c cung c·∫•p
DATABASE_URL = os.getenv("DATABASE_URL")

# C·∫•u h√¨nh Ollama (Cloud ho·∫∑c Local)
OLLAMA_HOST = "https://ollama.com"
MODEL_NAME = "gpt-oss:120b"
# API Key (∆Øu ti√™n l·∫•y t·ª´ .env)
DEFAULT_API_KEY = os.getenv("OLLAMA_API_KEY") 

# BI·∫æN TO√ÄN C·ª§C: Ch·ª©a danh s√°ch c√°c Documents (Chunks) ƒë·ªÉ l√†m RAG
GLOBAL_SCHEMA_DOCS = []

# =========================================================
#  PH·∫¶N 3: QU·∫¢N L√ù DATABASE (POSTGRESQL) - L∆ØU L·ªäCH S·ª¨ CHAT
# =========================================================
def get_db_connection():
    """T·∫°o k·∫øt n·ªëi ƒë·∫øn PostgreSQL"""
    if not DATABASE_URL:
        print("‚ùå L·ªói: Ch∆∞a c·∫•u h√¨nh DATABASE_URL trong .env ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng!")
        return None
    try:
        conn = psycopg2.connect(DATABASE_URL)
        return conn
    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi Database: {e}")
        return None

def init_db():
    """Kh·ªüi t·∫°o database PostgreSQL n·∫øu ch∆∞a c√≥ b·∫£ng"""
    conn = get_db_connection()
    if not conn: return

    try:
        cur = conn.cursor()
        # T·∫°o b·∫£ng sessions
        cur.execute('''CREATE TABLE IF NOT EXISTS sessions 
                     (id TEXT PRIMARY KEY, title TEXT, created_at TIMESTAMP)''')
        
        # T·∫°o b·∫£ng messages (D√πng SERIAL cho id t·ª± tƒÉng trong Postgres)
        cur.execute('''CREATE TABLE IF NOT EXISTS messages 
                     (id SERIAL PRIMARY KEY, session_id TEXT, role TEXT, content TEXT, created_at TIMESTAMP)''')
        
        conn.commit()
        cur.close()
        conn.close()
        print("‚úÖ ƒê√£ kh·ªüi t·∫°o Database PostgreSQL th√†nh c√¥ng.")
    except Exception as e:
        print(f"‚ùå L·ªói kh·ªüi t·∫°o Database: {e}")

def get_chat_history_formatted(session_id, limit=10):
    """L·∫•y l·ªãch s·ª≠ chat c·ªßa m·ªôt phi√™n c·ª• th·ªÉ"""
    conn = get_db_connection()
    if not conn: return []
    
    try:
        # S·ª≠ d·ª•ng RealDictCursor ƒë·ªÉ l·∫•y d·ªØ li·ªáu d·∫°ng Dictionary
        cur = conn.cursor(cursor_factory=RealDictCursor)
        # Postgres d√πng %s thay v√¨ ? cho tham s·ªë
        cur.execute("SELECT role, content FROM messages WHERE session_id = %s ORDER BY created_at DESC LIMIT %s", (session_id, limit))
        rows = cur.fetchall()
        
        conn.close()
        
        history = []
        # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ x·∫øp theo th·ª© t·ª± th·ªùi gian c≈© -> m·ªõi
        for r in rows[::-1]:
            history.append({"role": r["role"], "content": r["content"]})
        return history
    except Exception as e:
        print(f"L·ªói l·∫•y l·ªãch s·ª≠: {e}")
        return []

def save_message(session_id, role, content):
    """L∆∞u tin nh·∫Øn v√†o DB"""
    conn = get_db_connection()
    if not conn: return

    try:
        cur = conn.cursor()
        cur.execute("INSERT INTO messages (session_id, role, content, created_at) VALUES (%s, %s, %s, %s)", 
                  (session_id, role, content, datetime.datetime.now()))
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"L·ªói l∆∞u tin nh·∫Øn: {e}")

def create_session_if_not_exists(session_id, first_msg):
    """T·∫°o phi√™n chat m·ªõi n·∫øu ch∆∞a t·ªìn t·∫°i"""
    conn = get_db_connection()
    if not conn: return

    try:
        cur = conn.cursor()
        cur.execute("SELECT id FROM sessions WHERE id = %s", (session_id,))
        if not cur.fetchone():
            # L·∫•y 50 k√Ω t·ª± ƒë·∫ßu c·ªßa tin nh·∫Øn l√†m ti√™u ƒë·ªÅ
            cur.execute("INSERT INTO sessions (id, title, created_at) VALUES (%s, %s, %s)", 
                      (session_id, first_msg[:50], datetime.datetime.now()))
            conn.commit()
        conn.close()
    except Exception as e:
        print(f"L·ªói t·∫°o session: {e}")

# =========================================================
#  PH·∫¶N 4: K·ª∏ THU·∫¨T RAG (RETRIEVAL AUGMENTED GENERATION)
# =========================================================
def load_all_schemas():
    """
    K·ªπ thu·∫≠t Advanced: ƒê·ªçc T·∫§T C·∫¢ file schemas v√† Indexing cho RAG.
    Thay v√¨ g·ªôp th√†nh 1 chu·ªói, ta l∆∞u th√†nh t·ª´ng m·∫£nh (document) ƒë·ªÉ t√¨m ki·∫øm.
    """
    global GLOBAL_SCHEMA_DOCS
    print("üöÄ ƒêang n·∫°p Schemas v√† Indexing cho RAG...")
    
    if not os.path.exists(SCHEMA_FOLDER): 
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c {SCHEMA_FOLDER}")
        return

    json_files = glob.glob(os.path.join(SCHEMA_FOLDER, "*.json"))
    GLOBAL_SCHEMA_DOCS = [] # Reset list
    
    for file_path in json_files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                items = data if isinstance(data, list) else [data]
                
                for item in items:
                    # --- X·ª¨ L√ù TABLE (B·∫¢NG) ---
                    if 'table_name' in item:
                        name = item.get('table_name', 'Unknown')
                        ddl = item.get('ddl', '')
                        
                        doc_content = f"""
[TABLE SCHEMA]
Name: `{name}`
DDL:
```sql
{ddl}
```
"""
                        GLOBAL_SCHEMA_DOCS.append({
                            "name": name,
                            "type": "TABLE",
                            "content": doc_content,
                            "keywords": f"{name} {ddl}".lower() # Index keywords
                        })
                    
                    # --- X·ª¨ L√ù ROUTINE (H√ÄM) ---
                    elif 'routine_name' in item:
                        name = item.get('routine_name', 'Unknown')
                        ddl = item.get('ddl', '')
                        definition = item.get('routine_definition', '')
                        arguments = item.get('arguments', [])
                        
                        # Format arguments
                        if isinstance(arguments, (list, dict)):
                            args_str = json.dumps(arguments, ensure_ascii=False)
                        else:
                            args_str = str(arguments)
                        
                        code_content = ddl if ddl else definition
                        
                        doc_content = f"""
[ROUTINE / FUNCTION]
Name: `{name}`
Arguments: {args_str}
DEFINITION (SOURCE SQL CODE):
```sql
{code_content}
```
(AI NOTE: H√£y ƒë·ªçc k·ªπ code SQL tr√™n. N·∫øu c√≥ CASE WHEN, h√£y d√πng n√≥ ƒë·ªÉ map gi√° tr·ªã ID t∆∞∆°ng ·ª©ng)
"""
                        GLOBAL_SCHEMA_DOCS.append({
                            "name": name,
                            "type": "ROUTINE",
                            "content": doc_content,
                            "keywords": f"{name} {code_content}".lower()
                        })

        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc file {file_path}: {e}")

    print(f"‚úÖ ƒê√£ n·∫°p {len(GLOBAL_SCHEMA_DOCS)} documents v√†o b·ªô nh·ªõ RAG.")

def search_relevant_schemas(query, top_k=10):
    """
    H√†m RAG Retrieval: T√¨m ki·∫øm schema li√™n quan d·ª±a tr√™n t·ª´ kh√≥a.
    """
    if not GLOBAL_SCHEMA_DOCS:
        return []
    
    query_lower = query.lower()
    query_tokens = set(query_lower.split())
    
    scored_docs = []
    
    for doc in GLOBAL_SCHEMA_DOCS:
        score = 0
        doc_keywords = doc['keywords']
        
        # 1. ∆Øu ti√™n kh·ªõp t√™n b·∫£ng/h√†m (Tr·ªçng s·ªë cao)
        if doc['name'].lower() in query_lower:
            score += 20
            
        # 2. Kh·ªõp t·ª´ng t·ª´ kh√≥a
        for token in query_tokens:
            if len(token) > 2 and token in doc_keywords:
                score += 1
        
        if score > 0:
            scored_docs.append((score, doc['content']))
    
    # S·∫Øp x·∫øp theo ƒëi·ªÉm gi·∫£m d·∫ßn
    scored_docs.sort(key=lambda x: x[0], reverse=True)
    
    # L·∫•y top K k·∫øt qu·∫£
    relevant_chunks = [item[1] for item in scored_docs[:top_k]]
    
    # Fallback: Tr·∫£ v·ªÅ m·ªôt √≠t n·∫øu kh√¥ng t√¨m th·∫•y g√¨ ƒë·ªÉ AI kh√¥ng b·ªã m√π
    if not relevant_chunks and GLOBAL_SCHEMA_DOCS:
        return [doc['content'] for doc in GLOBAL_SCHEMA_DOCS[:3]]
        
    return relevant_chunks

# --- KH·ªûI CH·∫†Y L·∫¶N ƒê·∫¶U ---
# ƒê·∫£m b·∫£o ch·∫°y khi file ƒë∆∞·ª£c import ho·∫∑c th·ª±c thi
init_db()
load_all_schemas()

# =========================================================
#  PH·∫¶N 5: API ROUTES & LOGIC CHAT
# =========================================================

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/sessions', methods=['GET'])
def get_sessions():
    """API l·∫•y danh s√°ch c√°c phi√™n chat"""
    conn = get_db_connection()
    if not conn: return jsonify([])
    
    try:
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("SELECT * FROM sessions ORDER BY created_at DESC")
        rows = cur.fetchall()
        conn.close()
        return jsonify([dict(r) for r in rows])
    except Exception as e:
        print(f"L·ªói l·∫•y danh s√°ch session: {e}")
        return jsonify([])

@app.route('/api/history/<session_id>', methods=['GET'])
def get_history(session_id): 
    """API l·∫•y n·ªôi dung chat"""
    return jsonify(get_chat_history_formatted(session_id, limit=50))

@app.route('/api/chat', methods=['POST'])
def chat():
    # S·ª≠ d·ª•ng logic RAG thay v√¨ Global Full Schema
    data = request.json
    api_key = data.get('api_key') or DEFAULT_API_KEY
    user_msg = data.get('message')
    session_id = data.get('session_id')

    if not api_key: return jsonify({"error": "Thi·∫øu API Key"}), 401
    if not session_id: return jsonify({"error": "Thi·∫øu Session ID"}), 400

    try:
        # 1. L∆∞u Session v√† Tin nh·∫Øn User
        create_session_if_not_exists(session_id, user_msg)
        save_message(session_id, "user", user_msg)

        # 2. RAG RETRIEVAL: T√¨m c√°c Schema li√™n quan
        print(f"üîç ƒêang t√¨m schema li√™n quan cho c√¢u h·ªèi: {user_msg}")
        relevant_schemas = search_relevant_schemas(user_msg, top_k=8)
        
        rag_context = "\n----------------------------------------\n".join(relevant_schemas)
        if not rag_context:
            rag_context = "(Kh√¥ng t√¨m th·∫•y b·∫£ng n√†o kh·ªõp r√µ r·ªát. H√£y d√πng ki·∫øn th·ª©c SQL chung.)"

        # 3. X√ÇY D·ª∞NG PROMPT (V·ªõi context ƒë√£ ƒë∆∞·ª£c l·ªçc g·ªçn)
        system_prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia BigQuery SQL cao c·∫•p.

[RAG CONTEXT - D·ªÆ LI·ªÜU LI√äN QUAN NH·∫§T]:
H·ªá th·ªëng ƒë√£ t·ª± ƒë·ªông l·ªçc ra c√°c B·∫£ng v√† H√†m c√≥ kh·∫£ nƒÉng li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa user.
Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin n√†y ƒë·ªÉ vi·∫øt query:

{rag_context}

[Y√äU C·∫¶U]:
Vi·∫øt c√¢u l·ªánh SQL Standard tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa user.

[QUY T·∫ÆC QUAN TR·ªåNG - B·∫ÆT BU·ªòC TU√ÇN TH·ª¶]:
1. **Logic Mapping (QUAN TR·ªåNG NH·∫§T):**
   - H√£y t·ª± ƒë·ªçc ph·∫ßn `[ROUTINE / FUNCTION]` ·ªü tr√™n.
   - T√¨m c√°c m·ªánh ƒë·ªÅ `CASE WHEN` b√™n trong code SQL c·ªßa routine ƒë·ªÉ hi·ªÉu √Ω nghƒ©a c√°c con s·ªë (ID).
   - V√≠ d·ª•: N·∫øu th·∫•y `WHEN status_id = 2 THEN 'New'`, v√† user h·ªèi v·ªÅ 'New', b·∫°n PH·∫¢I d√πng `status_id = 2`.
   - KH√îNG ƒê∆Ø·ª¢C ƒêO√ÅN M√í. N·∫øu routine ƒë·ªãnh nghƒ©a kh√°c, h√£y theo routine.

2. **K·ªπ thu·∫≠t BigQuery:**
   - ‚ùå KH√îNG d√πng Correlated Subqueries (Subquery ph·ª• thu·ªôc b·∫£ng ngo√†i).
   - ‚úÖ D√πng JOIN (LEFT JOIN) k·∫øt h·ª£p GROUP BY n·∫øu c·∫ßn.
   - Ph·∫£i s·ª≠ d·ª•ng c√°c h√†m, syntax theo chu·∫©n c·∫•u tr√∫c c·ªßa BigQuery.

3. Ch·ªâ tr·∫£ v·ªÅ code SQL trong ```sql ... ```.

4. C√≥ th·ªÉ gi·∫£i th√≠ch ng·∫Øn g·ªçn sau ph·∫ßn code n·∫øu c·∫ßn thi·∫øt.
"""

        messages_payload = [{"role": "system", "content": system_prompt}]
        
        # Th√™m l·ªãch s·ª≠ chat g·∫ßn nh·∫•t
        history = get_chat_history_formatted(session_id, limit=5)
        for msg in history:
            if msg['content'] != user_msg: 
                messages_payload.append(msg)
        
        # Th√™m c√¢u h·ªèi hi·ªán t·∫°i
        messages_payload.append({"role": "user", "content": user_msg})

        # 4. G·ªçi AI
        client = Client(host=OLLAMA_HOST, headers={"Authorization": f"Bearer {api_key}"})
        
        try:
            response = client.chat(
                model=MODEL_NAME, 
                messages=messages_payload, 
                stream=False, 
                options={"temperature": 0.1}
            )
            ai_reply = response['message']['content']
        except Exception as ollama_error:
            # X·ª≠ l√Ω l·ªói token limit n·∫øu v·∫´n b·ªã
            err_msg = str(ollama_error)
            print(f"‚ö†Ô∏è L·ªói g·ªçi AI: {err_msg}")
            
            if "too long" in err_msg or "400" in err_msg:
                print("‚ö†Ô∏è Context v·∫´n d√†i, th·ª≠ l·∫°i v·ªõi √≠t schema h∆°n...")
                less_relevant = search_relevant_schemas(user_msg, top_k=3)
                less_context = "\n".join(less_relevant)
                
                messages_payload[0]['content'] = system_prompt.replace(rag_context, less_context)
                
                response = client.chat(
                    model=MODEL_NAME, 
                    messages=messages_payload, 
                    stream=False, 
                    options={"temperature": 0.1}
                )
                ai_reply = response['message']['content']
            else:
                return jsonify({"error": f"L·ªói AI: {err_msg}"}), 500

        # 5. L∆∞u c√¢u tr·∫£ l·ªùi c·ªßa AI
        save_message(session_id, "assistant", ai_reply)

        return jsonify({"response": ai_reply})

    except Exception as e:
        print(f"L·ªói Server: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/reload', methods=['POST'])
def reload_schema():
    """API ƒë·ªÉ n·∫°p l·∫°i d·ªØ li·ªáu khi b·∫°n s·ª≠a file JSON"""
    load_all_schemas()
    return jsonify({"status": "success", "message": "ƒê√£ n·∫°p l·∫°i v√† re-index d·ªØ li·ªáu cho RAG!"})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
